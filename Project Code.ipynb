{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e52bb441edda4997859f675745e97fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8753d50c16ce4870b7a325a11a6acb4e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24500cc185e9473a96f88a92e401a0b1",
              "IPY_MODEL_d4d6d95135a14be79776559d85991b43"
            ]
          }
        },
        "8753d50c16ce4870b7a325a11a6acb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24500cc185e9473a96f88a92e401a0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa6b50009f3742c9bcaa3f526b130394",
            "_dom_classes": [],
            "description": "Optimization Progress: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 48,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac732ab0cea94df786a54ae37b89c4e0"
          }
        },
        "d4d6d95135a14be79776559d85991b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35feae7ed2334dbc9f140b50d282934c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48/48 [05:18&lt;00:00,  5.72s/pipeline]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c22eaf851e343ee8b2c0e3e35c2eb75"
          }
        },
        "fa6b50009f3742c9bcaa3f526b130394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac732ab0cea94df786a54ae37b89c4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35feae7ed2334dbc9f140b50d282934c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c22eaf851e343ee8b2c0e3e35c2eb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4yU7S2rV3_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced0397e-5eb6-4c54-aa37-5f30cbd6f7cb"
      },
      "source": [
        "!pip install TPOT\n",
        "import tensorflow\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "import numpy as np\n",
        "from tpot import TPOTClassifier\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting TPOT\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/55/a7185198f554ea19758e5ac4641f100c94cba4585e738e2e48e3c40a0b7f/TPOT-0.11.7-py3-none-any.whl (87kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from TPOT) (1.0.1)\n",
            "Collecting update-checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from TPOT) (0.22.2.post1)\n",
            "Collecting deap>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/d1/803c7a387d8a7e6866160b1541307f88d534da4291572fb32f69d2548afb/deap-1.3.1-cp37-cp37m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 7.0MB/s \n",
            "\u001b[?25hCollecting stopit>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Collecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/35/169eec194bf1f9ef52ed670f5032ef2abaf6ed285cfadcb4b6026b800fc9/xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7MB 99kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from TPOT) (4.41.1)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from TPOT) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from TPOT) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from TPOT) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from update-checker>=0.16->TPOT) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->TPOT) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->TPOT) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->update-checker>=0.16->TPOT) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->TPOT) (1.15.0)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp37-none-any.whl size=11954 sha256=d3f121daf1ad3be41416dd16e845b3c98e1d6fe6c217fda033ea483be8ce4e0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built stopit\n",
            "Installing collected packages: update-checker, deap, stopit, xgboost, TPOT\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed TPOT-0.11.7 deap-1.3.1 stopit-1.1.2 update-checker-0.18.0 xgboost-1.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoQhHVMXWwYm"
      },
      "source": [
        "# **Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKck4pCvWZH8"
      },
      "source": [
        "# Loading the iris flower dataset\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data \n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL1i569sEUhF"
      },
      "source": [
        "# Loading the Fashion MNIST data\n",
        "# (fx_train, fy_train), (fx_test,fy_test) = tensorflow.keras.datasets.fashion_mnist.load_data()\n",
        "# fx_train = fx_train.reshape(fx_train.shape[0],fx_train.shape[1] * fx_train.shape[2])\n",
        "# fx_test = fx_test.reshape(fx_test.shape[0],fx_test.shape[1] * fx_test.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl_QPZpiXRsH"
      },
      "source": [
        "# **Splitting and preprocessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYOQibfIXVBc"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import copy\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25 , random_state = 21)\n",
        "y_train_gen = copy.deepcopy(y_train)\n",
        "y_test_gen = copy.deepcopy(y_test)\n",
        "x_train = preprocessing.normalize(x_train)\n",
        "x_test = preprocessing.normalize(x_test)\n",
        "x_train = x_train*2 - 1\n",
        "x_test = x_test*2 - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw_HmJbkaxbC"
      },
      "source": [
        "# **Classification Problem with Random Forest Classifier by selecting hyper-parameters ourself**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRttXBWFXeeD",
        "outputId": "c9a65731-746b-4a03-9d85-c8c90b468674"
      },
      "source": [
        "rfc = RandomForestClassifier(criterion = \"gini\", max_depth = 50, max_features = 'log2', \n",
        "                               min_samples_leaf = 0.25, min_samples_split = 0.5, n_estimators = 50,\n",
        "                             )\n",
        "rfc.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=50, max_features='log2',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.25, min_samples_split=0.5,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myvq-KzSbi5s"
      },
      "source": [
        "pred = rfc.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9dPW2Oub_mN",
        "outputId": "550cba83-c45b-4a36-9595-05dcfc9650f5"
      },
      "source": [
        "print(\"Accuracy = \", accuracy_score(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.8421052631578947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_kA4o3RcPtN",
        "outputId": "6677c33a-edc1-4780-b492-652248d73523"
      },
      "source": [
        "rfc.get_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=50, max_features='log2',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.25, min_samples_split=0.5,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QoaOOWmclgP"
      },
      "source": [
        "# **Bayesian optimization for hyperparameter search in Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn51grsocRUD"
      },
      "source": [
        "def Optimization(search_space):\n",
        "\n",
        "  estimators = search_space['n_estimators']\n",
        "  criterion = search_space['criterion']\n",
        "  depth = search_space['max_depth']\n",
        "  features = search_space['max_features']\n",
        "  leaf = search_space['min_samples_leaf']\n",
        "  split = search_space['min_samples_split']\n",
        "\n",
        "  rfc_model = RandomForestClassifier(criterion = criterion, max_depth = depth, max_features = features, \n",
        "                               min_samples_leaf = leaf, min_samples_split = split, n_estimators = estimators,\n",
        "                              )\n",
        "    \n",
        "  accuracy = cross_val_score(rfc_model, x_train, y_train, cv = 5).mean()\n",
        "  return {'loss': -accuracy, 'status': STATUS_OK }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evEWmoYgZqvQ"
      },
      "source": [
        "Defining the search space for bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TurdLA7LZkQ9"
      },
      "source": [
        "c = ['entropy', 'gini']\n",
        "f = ['auto', 'sqrt','log2', None]\n",
        "d = np.arange(start = 10 , stop = 1001 , step = 10)\n",
        "n = np.arange(start = 50 , stop = 1501 , step = 50)\n",
        "\n",
        "\n",
        "search_space = {'criterion': hp.choice('criterion', c ),\n",
        "        'max_depth': hp.choice('max_depth', d),\n",
        "        'max_features': hp.choice('max_features', f),\n",
        "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
        "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
        "        'n_estimators' : hp.choice('n_estimators', n)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg-jikNTZ48x",
        "outputId": "a6a3fe6d-4ca4-4f67-ab9b-b32fcd90397b"
      },
      "source": [
        "params = fmin(fn= Optimization,  space= search_space, algo= tpe.suggest, max_evals = 10, trials= Trials())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:06<00:00,  6.67s/it, best loss: -0.9640316205533596]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rDnJ7KecoCC",
        "outputId": "02dc6f6a-10e5-47f9-cdd0-785d1491dfe6"
      },
      "source": [
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 0,\n",
              " 'max_depth': 8,\n",
              " 'max_features': 2,\n",
              " 'min_samples_leaf': 0.053191156309751964,\n",
              " 'min_samples_split': 0.2323689936847898,\n",
              " 'n_estimators': 14}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6noSrGlffqbg"
      },
      "source": [
        "rfc_bayes = RandomForestClassifier( n_estimators = n[params['n_estimators']] ,criterion = c[params['criterion']] ,\n",
        "                             max_depth = d[params['max_depth']] , max_features = f[params['max_features']] ,\n",
        "                             min_samples_leaf = params['min_samples_leaf'] , min_samples_split = params['min_samples_split']\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96mevO4pjrTT",
        "outputId": "d82652d4-aaa4-463e-d966-33e6d764b292"
      },
      "source": [
        "rfc_bayes.fit(x_train , y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=90, max_features='log2',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=0.053191156309751964,\n",
              "                       min_samples_split=0.2323689936847898,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=750,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxPN8nJ9jz-H",
        "outputId": "8fb10152-a1dc-4048-ea38-cee41e8bff12"
      },
      "source": [
        "pred = rfc_bayes.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "print(\"Accuracy = \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAfUsf7ij7fx"
      },
      "source": [
        "# **Genetic Algorithm for Hyperparameter search in Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAUwaPiBkopH"
      },
      "source": [
        "Defining the search space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lYKr2Z1j6fp"
      },
      "source": [
        "c = ['entropy', 'gini']\n",
        "f = ['auto', 'sqrt','log2', None]\n",
        "d = np.arange(start = 10 , stop = 1000 , step = 10)\n",
        "n = np.arange(start = 50 , stop = 1501 , step = 50)\n",
        "split = np.arange(0, 1, 0.001)\n",
        "leaf = np.arange(0, 0.5, 0.001)\n",
        "\n",
        "search_space = {'n_estimators': n,'criterion': c, 'max_features': f, 'max_depth': d,\n",
        "                'min_samples_split': split, 'min_samples_leaf': leaf\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNwANkLbmELb"
      },
      "source": [
        "rfc_tpot = TPOTClassifier(generations= 2, population_size= 24, offspring_size= 12,\n",
        "                                 verbosity= 2, early_stop= 12,\n",
        "                                 config_dict={'sklearn.ensemble.RandomForestClassifier': search_space}, \n",
        "                                 cv = 5, scoring = 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "e52bb441edda4997859f675745e97fa0",
            "8753d50c16ce4870b7a325a11a6acb4e",
            "24500cc185e9473a96f88a92e401a0b1",
            "d4d6d95135a14be79776559d85991b43",
            "fa6b50009f3742c9bcaa3f526b130394",
            "ac732ab0cea94df786a54ae37b89c4e0",
            "35feae7ed2334dbc9f140b50d282934c",
            "9c22eaf851e343ee8b2c0e3e35c2eb75"
          ]
        },
        "id": "zbix2dZJmjZY",
        "outputId": "15212542-7cf4-495d-c1db-4683e11beb61"
      },
      "source": [
        "rfc_tpot.fit(x_train , y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e52bb441edda4997859f675745e97fa0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=48.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Generation 1 - Current best internal CV score: 0.9640316205533596\n",
            "\n",
            "Generation 2 - Current best internal CV score: 0.9640316205533596\n",
            "\n",
            "Best pipeline: RandomForestClassifier(CombineDFs(input_matrix, input_matrix), criterion=entropy, max_depth=990, max_features=sqrt, min_samples_leaf=0.05, min_samples_split=0.196, n_estimators=1350)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict={'sklearn.ensemble.RandomForestClassifier': {'criterion': ['entropy',\n",
              "                                                                                      'gini'],\n",
              "                                                                        'max_depth': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
              "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260,\n",
              "       270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390,\n",
              "       400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520,\n",
              "       530, 540, 550, 560, 570, 580, 590, 60...\n",
              "               crossover_rate=0.1, cv=5, disable_update_check=False,\n",
              "               early_stop=12, generations=2, log_file=None,\n",
              "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "               mutation_rate=0.9, n_jobs=1, offspring_size=12,\n",
              "               periodic_checkpoint_folder=None, population_size=24,\n",
              "               random_state=None, scoring='accuracy', subsample=1.0,\n",
              "               template=None, use_dask=False, verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAwntwvyrkzU",
        "outputId": "3620eaee-9a03-4720-8e95-840cb32ce55a"
      },
      "source": [
        "accuracy = rfc_tpot.score(x_test, y_test)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9473684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H71SiQwD0hNK"
      },
      "source": [
        "# **Classification Problem with deep neural network architecture by selecting hyper-parameters ourself**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmRl9LSX1tWG"
      },
      "source": [
        "Defining the search space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U41ODLV84HvS"
      },
      "source": [
        "!pip install hyperas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWAengCM7ief"
      },
      "source": [
        "!pip install np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeE81Qzn10v5"
      },
      "source": [
        "import hyperas\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZo0kZwr6rTs"
      },
      "source": [
        "classes = 3\n",
        "y_train = to_categorical(y_train, classes)\n",
        "y_test = to_categorical(y_test, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObyUbGhTKmJB"
      },
      "source": [
        "# **Defining the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCDMoMx_KlPo",
        "outputId": "798c34ac-1626-4201-a762-ec0c2dc93655"
      },
      "source": [
        "initial_model = Sequential()\n",
        "\n",
        "initial_model.add(Dense(512, input_shape=(4,)))\n",
        "initial_model.add(Activation(\"relu\"))\n",
        "initial_model.add(Dropout(0.2))\n",
        "\n",
        "initial_model.add(Dense(256))\n",
        "initial_model.add(Activation(\"relu\"))\n",
        "initial_model.add(Dropout(0.2))\n",
        "\n",
        "initial_model.add(Dense(classes))\n",
        "initial_model.add(Activation('softmax'))\n",
        "\n",
        "initial_model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=\"adam\")\n",
        "initial_model.fit(x_train, y_train,\n",
        "              batch_size=64,\n",
        "              epochs=20,              \n",
        "              validation_split = 0.2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 206ms/step - loss: 1.0941 - accuracy: 0.3820 - val_loss: 1.0540 - val_accuracy: 0.6087\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.0199 - accuracy: 0.7191 - val_loss: 1.0135 - val_accuracy: 0.6087\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.9593 - accuracy: 0.7079 - val_loss: 0.9745 - val_accuracy: 0.6087\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.8985 - accuracy: 0.7079 - val_loss: 0.9326 - val_accuracy: 0.6087\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.8316 - accuracy: 0.7079 - val_loss: 0.8849 - val_accuracy: 0.6087\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.7696 - accuracy: 0.7191 - val_loss: 0.8319 - val_accuracy: 0.6087\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7089 - accuracy: 0.7191 - val_loss: 0.7748 - val_accuracy: 0.6087\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.6502 - accuracy: 0.7191 - val_loss: 0.7229 - val_accuracy: 0.6087\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.5817 - accuracy: 0.7303 - val_loss: 0.6759 - val_accuracy: 0.6522\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.5399 - accuracy: 0.7191 - val_loss: 0.6322 - val_accuracy: 0.6522\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.4992 - accuracy: 0.7528 - val_loss: 0.5943 - val_accuracy: 0.6522\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4665 - accuracy: 0.7416 - val_loss: 0.5608 - val_accuracy: 0.6957\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4255 - accuracy: 0.7978 - val_loss: 0.5277 - val_accuracy: 0.8696\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3930 - accuracy: 0.8539 - val_loss: 0.5000 - val_accuracy: 0.8696\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.3729 - accuracy: 0.9213 - val_loss: 0.4755 - val_accuracy: 0.8696\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3502 - accuracy: 0.9326 - val_loss: 0.4523 - val_accuracy: 0.9130\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3212 - accuracy: 0.9551 - val_loss: 0.4297 - val_accuracy: 0.9130\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3085 - accuracy: 0.9213 - val_loss: 0.4093 - val_accuracy: 0.9130\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2852 - accuracy: 0.9438 - val_loss: 0.3922 - val_accuracy: 0.8696\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2820 - accuracy: 0.9438 - val_loss: 0.3756 - val_accuracy: 0.9130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb57032ce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBktlEkYLaoy",
        "outputId": "9eb3ae6d-5dde-487f-a359-dff241e6a19f"
      },
      "source": [
        "score, acc = initial_model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.9211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzfsDP4kJ-G_"
      },
      "source": [
        "# **Bayesian Optimization for Hyperparameter search on deep neural network architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XSZnvBXrIIj"
      },
      "source": [
        "Defining the search space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR6MkMzc2VDJ"
      },
      "source": [
        "hlayers = [ 2, 3 , 4 , 5]\n",
        "hidden_units = [ 64, 128, 256, 512 , 1024 ]\n",
        "activation = [ 'relu' , 'sigmoid']\n",
        "optimizer = ['adam', 'rmsprop', 'sgd']\n",
        "batch_size = [ 64, 128, 256 , 512]\n",
        "lr = [ 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
        "epochs = np.arange(start = 10, stop = 101, step = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS7d1ovTJ_OS"
      },
      "source": [
        "space = {'Dense1': hp.choice('Dense1', hidden_units ),\n",
        "         'Dense2': hp.choice('Dense2', hidden_units ),\n",
        "         'Dense3': hp.choice('Dense3', hidden_units ),\n",
        "         'Dense4': hp.choice('Dense4', hidden_units ),\n",
        "         'Dense5': hp.choice('Dense5', hidden_units ),\n",
        "         'Dense6': hp.choice('Dense6', hidden_units ),\n",
        "         'Activation1': hp.choice('Activation1', activation ),\n",
        "         'Activation2': hp.choice('Activation2', activation ),\n",
        "        #  'Activation3': hp.choice('Activation3', activation ),\n",
        "\n",
        "         'Dropout1': hp.uniform('Dropout1', 0, 1),\n",
        "         'Dropout2': hp.uniform('Dropout2', 0, 1),\n",
        "         'Dropout3': hp.uniform('Dropout3', 0, 1),\n",
        "         'Dropout4': hp.uniform('Dropout4', 0, 1),\n",
        "         'Dropout5': hp.uniform('Dropout5', 0, 1),\n",
        "         'Dropout6': hp.uniform('Dropout6', 0, 1),\n",
        "         \n",
        "         'hidden_layers': hp.choice('hidden_layers', hlayers),\n",
        "         'Optimizer': hp.choice('Optimizer', optimizer),\n",
        "\n",
        "         'learning_rate': hp.choice('learning_rate', lr),\n",
        "         'epochs': hp.choice('epochs' , epochs),\n",
        "        'batch_size': hp.choice('batch_size' , batch_size)\n",
        "\n",
        "        \n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqU3-jZ0Xo1k"
      },
      "source": [
        "def Optimization_deep(space):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(space['Dense1'], input_shape=(4,)))\n",
        "  model.add(Activation(space['Activation1']))\n",
        "  model.add(Dropout(space['Dropout1']))\n",
        "\n",
        "  model.add(Dense(space['Dense2']))\n",
        "  model.add(Activation(space['Activation2']))\n",
        "  model.add(Dropout(space['Dropout2']))\n",
        "    \n",
        "  if space['hidden_layers'] >=2:\n",
        "    model.add(Dense(space['Dense3']))\n",
        "    model.add(Activation(space['Activation2']))\n",
        "    model.add(Dropout(space['Dropout3']))\n",
        "\n",
        "  if space['hidden_layers'] >=3:\n",
        "    model.add(Dense(space['Dense4']))\n",
        "    model.add(Activation(space['Activation2']))\n",
        "    model.add(Dropout(space['Dropout4']))\n",
        "\n",
        "  if space['hidden_layers'] >=4:\n",
        "    model.add(Dense(space['Dense5']))\n",
        "    model.add(Activation(space['Activation2']))\n",
        "    model.add(Dropout(space['Dropout5']))\n",
        "\n",
        "  if space['hidden_layers'] == 5:\n",
        "    model.add(Dense(space['Dense6']))\n",
        "    model.add(Activation(space['Activation2']))\n",
        "    model.add(Dropout(space['Dropout6']))\n",
        "        \n",
        "  model.add(Dense(classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  adam = keras.optimizers.Adam(lr=space['learning_rate'])\n",
        "  rmsprop = keras.optimizers.RMSprop(lr=space['learning_rate'])\n",
        "  sgd = keras.optimizers.SGD(lr=space['learning_rate'])\n",
        "\n",
        "  temp = space['Optimizer']\n",
        "  if temp == 'adam':\n",
        "      optim = adam\n",
        "  elif temp == 'rmsprop':\n",
        "      optim = rmsprop\n",
        "  else:\n",
        "      optim = sgd\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
        "  model.fit(x_train, y_train,\n",
        "              batch_size = space['batch_size'],\n",
        "              epochs=space['epochs'],              \n",
        "              validation_split = 0.2)\n",
        "  score, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "  print('Test accuracy:', acc)\n",
        "  return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXFCvgGtY_6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69fa8d5-90e9-4752-a7e5-e1d364c348de"
      },
      "source": [
        "params = fmin(fn= Optimization_deep, space = space, algo= tpe.suggest, max_evals = 2, trials= Trials())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "  0%|          | 0/2 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2433 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 1s 205ms/step - loss: 4.8084 - accuracy: 0.3483 - val_loss: 3.5271 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 2/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 3.7538 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 56ms/step - loss: 4.1891 - accuracy: 0.3483 - val_loss: 7.5765 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 3/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 9.5623 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 58ms/step - loss: 9.7160 - accuracy: 0.2921 - val_loss: 2.5256 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 4/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 4.0968 - accuracy: 0.3594\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 66ms/step - loss: 4.2671 - accuracy: 0.3371 - val_loss: 5.4433 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 5/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 4.8916 - accuracy: 0.2969\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 61ms/step - loss: 4.5482 - accuracy: 0.3483 - val_loss: 5.9990 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 6/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 4.4075 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 62ms/step - loss: 4.0755 - accuracy: 0.3483 - val_loss: 1.5079 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 7/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.3305 - accuracy: 0.3281\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 63ms/step - loss: 2.4094 - accuracy: 0.3483 - val_loss: 2.2415 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 8/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 3.9503 - accuracy: 0.2500\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 67ms/step - loss: 3.9523 - accuracy: 0.2584 - val_loss: 1.6916 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 9/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.8834 - accuracy: 0.2812\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 63ms/step - loss: 2.6135 - accuracy: 0.2921 - val_loss: 2.2376 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 10/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.8005 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 55ms/step - loss: 2.1763 - accuracy: 0.3258 - val_loss: 2.9042 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 11/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.4342 - accuracy: 0.3594\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 55ms/step - loss: 2.1662 - accuracy: 0.3708 - val_loss: 1.1543 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 12/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.8082 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 56ms/step - loss: 1.9457 - accuracy: 0.3820 - val_loss: 1.6584 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 13/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.0852 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 55ms/step - loss: 2.0184 - accuracy: 0.3596 - val_loss: 1.5974 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 14/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.0253 - accuracy: 0.3281\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 54ms/step - loss: 2.0562 - accuracy: 0.3258 - val_loss: 2.4179 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 15/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.0445 - accuracy: 0.4375\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 66ms/step - loss: 2.0039 - accuracy: 0.3933 - val_loss: 1.2055 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 16/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.8755 - accuracy: 0.2812\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 56ms/step - loss: 1.9484 - accuracy: 0.2809 - val_loss: 1.3189 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 17/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.0901 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 67ms/step - loss: 2.0361 - accuracy: 0.2809 - val_loss: 1.3677 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 18/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3143 - accuracy: 0.3594\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 70ms/step - loss: 1.5909 - accuracy: 0.3483 - val_loss: 2.5150 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 19/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 2.2920 - accuracy: 0.3281\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 79ms/step - loss: 2.0272 - accuracy: 0.3258 - val_loss: 1.4165 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 20/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.6087 - accuracy: 0.3125\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 56ms/step - loss: 1.5369 - accuracy: 0.3146 - val_loss: 1.5301 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 21/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.6403 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 55ms/step - loss: 1.6894 - accuracy: 0.2697 - val_loss: 1.3976 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 22/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2980 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 59ms/step - loss: 1.3308 - accuracy: 0.3146 - val_loss: 1.2067 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 23/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4438 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 77ms/step - loss: 1.3795 - accuracy: 0.3820 - val_loss: 1.3121 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 24/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3194 - accuracy: 0.4531\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 64ms/step - loss: 1.2860 - accuracy: 0.4045 - val_loss: 1.3742 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 25/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3019 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 79ms/step - loss: 1.3486 - accuracy: 0.2360 - val_loss: 1.0630 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 26/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2172 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 59ms/step - loss: 1.1946 - accuracy: 0.3708 - val_loss: 1.2020 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 27/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3024 - accuracy: 0.3281\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 68ms/step - loss: 1.3807 - accuracy: 0.3034 - val_loss: 1.1430 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 28/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1463 - accuracy: 0.4062\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 87ms/step - loss: 1.2330 - accuracy: 0.3708 - val_loss: 1.3546 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 29/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.5210 - accuracy: 0.3125\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 55ms/step - loss: 1.5263 - accuracy: 0.3371 - val_loss: 1.6805 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 30/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4002 - accuracy: 0.4219\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 75ms/step - loss: 1.4596 - accuracy: 0.4045 - val_loss: 1.3096 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 31/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.6722 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 65ms/step - loss: 1.6394 - accuracy: 0.2697 - val_loss: 1.1518 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 32/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1758 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 66ms/step - loss: 1.2071 - accuracy: 0.3483 - val_loss: 1.4334 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 33/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2954 - accuracy: 0.5000\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 81ms/step - loss: 1.3307 - accuracy: 0.4382 - val_loss: 1.1025 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 34/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3175 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 71ms/step - loss: 1.4694 - accuracy: 0.3483 - val_loss: 1.0504 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 35/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2234 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 81ms/step - loss: 1.2955 - accuracy: 0.3371 - val_loss: 1.4507 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 36/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3040 - accuracy: 0.3906\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 63ms/step - loss: 1.3672 - accuracy: 0.3483 - val_loss: 1.0424 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 37/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3163 - accuracy: 0.3281\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 74ms/step - loss: 1.3324 - accuracy: 0.3146 - val_loss: 1.1923 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 38/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1379 - accuracy: 0.4531\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 63ms/step - loss: 1.2755 - accuracy: 0.4045 - val_loss: 1.1958 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 39/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1605 - accuracy: 0.2969\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 52ms/step - loss: 1.2116 - accuracy: 0.3146 - val_loss: 1.0816 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 40/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4497 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 57ms/step - loss: 1.3515 - accuracy: 0.3820 - val_loss: 1.3554 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 41/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3600 - accuracy: 0.2969\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 65ms/step - loss: 1.3190 - accuracy: 0.3483 - val_loss: 1.0579 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 42/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2606 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 67ms/step - loss: 1.2696 - accuracy: 0.3820 - val_loss: 1.1047 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 43/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4722 - accuracy: 0.2969\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 70ms/step - loss: 1.4311 - accuracy: 0.2697 - val_loss: 1.2922 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 44/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2942 - accuracy: 0.2812\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 81ms/step - loss: 1.3132 - accuracy: 0.2697 - val_loss: 1.0543 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 45/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3778 - accuracy: 0.2969\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 70ms/step - loss: 1.3145 - accuracy: 0.3146 - val_loss: 1.1515 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 46/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3743 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 56ms/step - loss: 1.3459 - accuracy: 0.2809 - val_loss: 1.5461 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 47/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2713 - accuracy: 0.4062\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 54ms/step - loss: 1.3403 - accuracy: 0.3933 - val_loss: 1.2110 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 48/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4572 - accuracy: 0.2969\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 79ms/step - loss: 1.6057 - accuracy: 0.2921 - val_loss: 1.0682 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 49/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3225 - accuracy: 0.3125\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 59ms/step - loss: 1.2796 - accuracy: 0.3371 - val_loss: 1.7171 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 50/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4851 - accuracy: 0.3906\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 60ms/step - loss: 1.4278 - accuracy: 0.3933 - val_loss: 1.0709 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 51/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4393 - accuracy: 0.2500\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 68ms/step - loss: 1.4161 - accuracy: 0.3258 - val_loss: 1.0353 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 52/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3420 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 76ms/step - loss: 1.4348 - accuracy: 0.3258 - val_loss: 1.3546 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 53/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.4068 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 65ms/step - loss: 1.3901 - accuracy: 0.3596 - val_loss: 1.0394 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 54/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3570 - accuracy: 0.3438\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 62ms/step - loss: 1.2964 - accuracy: 0.3483 - val_loss: 1.3545 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 55/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2412 - accuracy: 0.3906\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 64ms/step - loss: 1.3167 - accuracy: 0.3483 - val_loss: 1.2200 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 56/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3982 - accuracy: 0.2656\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 59ms/step - loss: 1.4061 - accuracy: 0.2697 - val_loss: 1.0550 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 57/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.2088 - accuracy: 0.3125\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 63ms/step - loss: 1.2374 - accuracy: 0.2697 - val_loss: 1.3075 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 58/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1676 - accuracy: 0.3594\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 67ms/step - loss: 1.1630 - accuracy: 0.3596 - val_loss: 1.2120 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 59/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1974 - accuracy: 0.4062\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 63ms/step - loss: 1.2119 - accuracy: 0.3820 - val_loss: 1.1121 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 60/60\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.3284 - accuracy: 0.2500\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 76ms/step - loss: 1.3465 - accuracy: 0.2697 - val_loss: 1.1350 - val_accuracy: 0.1739\n",
            "\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1263 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 18ms/step - loss: 1.1337 - accuracy: 0.3421\n",
            "\n",
            "Test accuracy:\n",
            "0.34210526943206787\n",
            "Epoch 1/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.4349 - accuracy: 0.3034\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 1s 750ms/step - loss: 1.4349 - accuracy: 0.3034 - val_loss: 1.3417 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 2/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.3108 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 91ms/step - loss: 1.3108 - accuracy: 0.3708 - val_loss: 1.3136 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 3/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.2981 - accuracy: 0.3034\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 96ms/step - loss: 1.2981 - accuracy: 0.3034 - val_loss: 1.1738 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 4/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.2445 - accuracy: 0.3371\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 87ms/step - loss: 1.2445 - accuracy: 0.3371 - val_loss: 1.0848 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 5/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1567 - accuracy: 0.3146\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 94ms/step - loss: 1.1567 - accuracy: 0.3146 - val_loss: 1.1449 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 6/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.2131 - accuracy: 0.3146\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 75ms/step - loss: 1.2131 - accuracy: 0.3146 - val_loss: 1.1993 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 7/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.2428 - accuracy: 0.4270\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 72ms/step - loss: 1.2428 - accuracy: 0.4270 - val_loss: 1.2080 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 8/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1707 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 82ms/step - loss: 1.1707 - accuracy: 0.4045 - val_loss: 1.2005 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 9/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1491 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 71ms/step - loss: 1.1491 - accuracy: 0.3483 - val_loss: 1.1755 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 10/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1205 - accuracy: 0.4494\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 83ms/step - loss: 1.1205 - accuracy: 0.4494 - val_loss: 1.1582 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 11/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0895 - accuracy: 0.3820\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 136ms/step - loss: 1.0895 - accuracy: 0.3820 - val_loss: 1.1547 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 12/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1962 - accuracy: 0.3034\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 114ms/step - loss: 1.1962 - accuracy: 0.3034 - val_loss: 1.1526 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 13/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1749 - accuracy: 0.3371\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 99ms/step - loss: 1.1749 - accuracy: 0.3371 - val_loss: 1.1450 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 14/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1424 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 98ms/step - loss: 1.1424 - accuracy: 0.3596 - val_loss: 1.1343 - val_accuracy: 0.3913\n",
            "\n",
            "Epoch 15/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1748 - accuracy: 0.2809\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 85ms/step - loss: 1.1748 - accuracy: 0.2809 - val_loss: 1.1289 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 16/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1516 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 88ms/step - loss: 1.1516 - accuracy: 0.3596 - val_loss: 1.1237 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 17/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0855 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 81ms/step - loss: 1.0855 - accuracy: 0.4045 - val_loss: 1.1264 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 18/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1192 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 86ms/step - loss: 1.1192 - accuracy: 0.3483 - val_loss: 1.1274 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 19/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1158 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 90ms/step - loss: 1.1158 - accuracy: 0.3483 - val_loss: 1.1317 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 20/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1097 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 70ms/step - loss: 1.1097 - accuracy: 0.4045 - val_loss: 1.1363 - val_accuracy: 0.4348\n",
            "\n",
            "Epoch 21/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1590 - accuracy: 0.3034\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 93ms/step - loss: 1.1590 - accuracy: 0.3034 - val_loss: 1.1411 - val_accuracy: 0.2609\n",
            "\n",
            "Epoch 22/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1093 - accuracy: 0.3146\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 100ms/step - loss: 1.1093 - accuracy: 0.3146 - val_loss: 1.1433 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 23/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1474 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 97ms/step - loss: 1.1474 - accuracy: 0.4045 - val_loss: 1.1444 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 24/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1536 - accuracy: 0.2809\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 87ms/step - loss: 1.1536 - accuracy: 0.2809 - val_loss: 1.1439 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 25/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0513 - accuracy: 0.4382\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 91ms/step - loss: 1.0513 - accuracy: 0.4382 - val_loss: 1.1420 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 26/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1095 - accuracy: 0.4382\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 91ms/step - loss: 1.1095 - accuracy: 0.4382 - val_loss: 1.1374 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 27/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1418 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 100ms/step - loss: 1.1418 - accuracy: 0.3483 - val_loss: 1.1318 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 28/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1192 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 95ms/step - loss: 1.1192 - accuracy: 0.4045 - val_loss: 1.1267 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 29/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1477 - accuracy: 0.2809\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 91ms/step - loss: 1.1477 - accuracy: 0.2809 - val_loss: 1.1223 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 30/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1088 - accuracy: 0.3258\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 78ms/step - loss: 1.1088 - accuracy: 0.3258 - val_loss: 1.1199 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 31/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1245 - accuracy: 0.3371\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 91ms/step - loss: 1.1245 - accuracy: 0.3371 - val_loss: 1.1182 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 32/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1277 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 87ms/step - loss: 1.1277 - accuracy: 0.3708 - val_loss: 1.1182 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 33/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1002 - accuracy: 0.2809\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 95ms/step - loss: 1.1002 - accuracy: 0.2809 - val_loss: 1.1189 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 34/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1143 - accuracy: 0.3371\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 112ms/step - loss: 1.1143 - accuracy: 0.3371 - val_loss: 1.1205 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 35/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0856 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 94ms/step - loss: 1.0856 - accuracy: 0.3708 - val_loss: 1.1233 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 36/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1275 - accuracy: 0.2697\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 96ms/step - loss: 1.1275 - accuracy: 0.2697 - val_loss: 1.1256 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 37/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0983 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 88ms/step - loss: 1.0983 - accuracy: 0.3708 - val_loss: 1.1267 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 38/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1070 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 95ms/step - loss: 1.1070 - accuracy: 0.3708 - val_loss: 1.1274 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 39/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0858 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 84ms/step - loss: 1.0858 - accuracy: 0.3483 - val_loss: 1.1266 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 40/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0947 - accuracy: 0.3258\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 74ms/step - loss: 1.0947 - accuracy: 0.3258 - val_loss: 1.1257 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 41/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0922 - accuracy: 0.3820\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 105ms/step - loss: 1.0922 - accuracy: 0.3820 - val_loss: 1.1243 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 42/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1109 - accuracy: 0.2921\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 85ms/step - loss: 1.1109 - accuracy: 0.2921 - val_loss: 1.1232 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 43/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1265 - accuracy: 0.3146\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 127ms/step - loss: 1.1265 - accuracy: 0.3146 - val_loss: 1.1222 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 44/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0841 - accuracy: 0.3146\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 90ms/step - loss: 1.0841 - accuracy: 0.3146 - val_loss: 1.1214 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 45/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1230 - accuracy: 0.2921\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 102ms/step - loss: 1.1230 - accuracy: 0.2921 - val_loss: 1.1208 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 46/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0983 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 100ms/step - loss: 1.0983 - accuracy: 0.3708 - val_loss: 1.1208 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 47/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1111 - accuracy: 0.3258\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 93ms/step - loss: 1.1111 - accuracy: 0.3258 - val_loss: 1.1209 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 48/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0855 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 108ms/step - loss: 1.0855 - accuracy: 0.4045 - val_loss: 1.1217 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 49/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0978 - accuracy: 0.3371\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 97ms/step - loss: 1.0978 - accuracy: 0.3371 - val_loss: 1.1230 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 50/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1005 - accuracy: 0.3933\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 142ms/step - loss: 1.1005 - accuracy: 0.3933 - val_loss: 1.1231 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 51/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1014 - accuracy: 0.3258\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 109ms/step - loss: 1.1014 - accuracy: 0.3258 - val_loss: 1.1233 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 52/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0832 - accuracy: 0.4270\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 109ms/step - loss: 1.0832 - accuracy: 0.4270 - val_loss: 1.1232 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 53/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0970 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 104ms/step - loss: 1.0970 - accuracy: 0.3708 - val_loss: 1.1226 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 54/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0863 - accuracy: 0.4382\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 94ms/step - loss: 1.0863 - accuracy: 0.4382 - val_loss: 1.1219 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 55/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0897 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 106ms/step - loss: 1.0897 - accuracy: 0.3596 - val_loss: 1.1218 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 56/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0801 - accuracy: 0.4270\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 101ms/step - loss: 1.0801 - accuracy: 0.4270 - val_loss: 1.1213 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 57/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0967 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 99ms/step - loss: 1.0967 - accuracy: 0.3483 - val_loss: 1.1204 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 58/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0963 - accuracy: 0.3933\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 94ms/step - loss: 1.0963 - accuracy: 0.3933 - val_loss: 1.1198 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 59/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0977 - accuracy: 0.4045\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 94ms/step - loss: 1.0977 - accuracy: 0.4045 - val_loss: 1.1190 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 60/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0953 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 81ms/step - loss: 1.0953 - accuracy: 0.3708 - val_loss: 1.1185 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 61/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0910 - accuracy: 0.3708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 124ms/step - loss: 1.0910 - accuracy: 0.3708 - val_loss: 1.1173 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 62/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0942 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 92ms/step - loss: 1.0942 - accuracy: 0.3483 - val_loss: 1.1162 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 63/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0832 - accuracy: 0.4270\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 91ms/step - loss: 1.0832 - accuracy: 0.4270 - val_loss: 1.1156 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 64/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0927 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 75ms/step - loss: 1.0927 - accuracy: 0.3596 - val_loss: 1.1153 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 65/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0978 - accuracy: 0.3483\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 111ms/step - loss: 1.0978 - accuracy: 0.3483 - val_loss: 1.1156 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 66/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0890 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 130ms/step - loss: 1.0890 - accuracy: 0.3596 - val_loss: 1.1154 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 67/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.1042 - accuracy: 0.3034\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 85ms/step - loss: 1.1042 - accuracy: 0.3034 - val_loss: 1.1153 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 68/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0945 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 112ms/step - loss: 1.0945 - accuracy: 0.3596 - val_loss: 1.1156 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 69/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0915 - accuracy: 0.4157\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 92ms/step - loss: 1.0915 - accuracy: 0.4157 - val_loss: 1.1162 - val_accuracy: 0.1739\n",
            "\n",
            "Epoch 70/70\n",
            "1/1 [==============================]\n",
            " - ETA: 0s - loss: 1.0910 - accuracy: 0.3596\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/1 [==============================]\n",
            " - 0s 98ms/step - loss: 1.0910 - accuracy: 0.3596 - val_loss: 1.1170 - val_accuracy: 0.1739\n",
            "\n",
            "1/2 [==============>...............]\n",
            " - ETA: 0s - loss: 1.1019 - accuracy: 0.3750\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/2 [==============================]\n",
            " - 0s 16ms/step - loss: 1.1068 - accuracy: 0.3421\n",
            "\n",
            "Test accuracy:\n",
            "0.34210526943206787\n",
            "100%|██████████| 2/2 [00:17<00:00,  8.91s/it, best loss: -0.34210526943206787]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WvS7t3ebxOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487b3985-3f36-46d2-c908-aeb71773e3c9"
      },
      "source": [
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Activation1': 1,\n",
              " 'Activation2': 1,\n",
              " 'Dense1': 0,\n",
              " 'Dense2': 2,\n",
              " 'Dense3': 3,\n",
              " 'Dense4': 0,\n",
              " 'Dense5': 2,\n",
              " 'Dense6': 0,\n",
              " 'Dropout1': 0.6013723972694217,\n",
              " 'Dropout2': 0.46456886074785797,\n",
              " 'Dropout3': 0.6924912143698925,\n",
              " 'Dropout4': 0.37205399676057294,\n",
              " 'Dropout5': 0.9347369555501416,\n",
              " 'Dropout6': 0.7105841632289172,\n",
              " 'Optimizer': 0,\n",
              " 'batch_size': 0,\n",
              " 'epochs': 5,\n",
              " 'hidden_layers': 1,\n",
              " 'learning_rate': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuK2Qo1INdLr"
      },
      "source": [
        "Testing neural network with the hyperparameters selected by Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnY4wWEhMw2t"
      },
      "source": [
        "final_model = Sequential()\n",
        "\n",
        "final_model.add(Dense(hidden_units[params['Dense1']], input_shape=(4,)))\n",
        "final_model.add(Activation(activation[params['Activation1']]))\n",
        "final_model.add(Dropout(params['Dropout1']))\n",
        "\n",
        "final_model.add(Dense(hidden_units[params['Dense2']]))\n",
        "final_model.add(Activation(activation[params['Activation2']]))\n",
        "final_model.add(Dropout(params['Dropout2']))\n",
        "    \n",
        "if hlayers[params['hidden_layers']] >=2:\n",
        "  final_model.add(Dense(hidden_units[params['Dense3']]))\n",
        "  final_model.add(Activation(activation[params['Activation2']]))\n",
        "  final_model.add(Dropout(params['Dropout3']))\n",
        "\n",
        "if hlayers[params['hidden_layers']] >= 3:\n",
        "  final_model.add(Dense(hidden_units[params['Dense4']]))\n",
        "  final_model.add(Activation(activation[params['Activation2']]))\n",
        "  final_model.add(Dropout(params['Dropout4']))\n",
        "\n",
        "if hlayers[params['hidden_layers']] >= 4:\n",
        "  final_model.add(Dense(hidden_units[params['Dense5']]))\n",
        "  final_model.add(Activation(activation[params['Activation2']]))\n",
        "  final_model.add(Dropout(params['Dropout5']))\n",
        "\n",
        "if hlayers[params['hidden_layers']] == 5:\n",
        "  final_model.add(Dense(hidden_units[params['Dense6']]))\n",
        "  final_model.add(Activation(activation[params['Activation2']]))\n",
        "  final_model.add(Dropout(params['Dropout6']))\n",
        "        \n",
        "final_model.add(Dense(classes))\n",
        "final_model.add(Activation('softmax'))\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=lr[params['learning_rate']])\n",
        "rmsprop = keras.optimizers.RMSprop(lr=lr[params['learning_rate']])\n",
        "sgd = keras.optimizers.SGD(lr=lr[params['learning_rate']])\n",
        "\n",
        "temp = optimizer[params['Optimizer']]\n",
        "if temp == 'adam':\n",
        "    optim = adam\n",
        "elif temp == 'rmsprop':\n",
        "    optim = rmsprop\n",
        "else:\n",
        "    optim = sgd\n",
        "\n",
        "final_model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
        "final_model.fit(x_train, y_train,\n",
        "            batch_size= batch_size[params['batch_size']],\n",
        "            epochs = epochs[params['epochs']],              \n",
        "            validation_split = 0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZslrlRsOvoL",
        "outputId": "7e731815-60a1-42fb-e015-d74d9296ebaf"
      },
      "source": [
        "score, acc = final_model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5495 - accuracy: 0.2632\n",
            "Test accuracy: 0.2631579041481018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNe_JMm6NqyD"
      },
      "source": [
        "# **Genetic Algorithm for hyperparameter search in deep neural network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k2jsbYsbzNe"
      },
      "source": [
        "hlayers = [ 2,3]\n",
        "hidden_units = [ 64, 128, 256, 512 , 1024 ]\n",
        "activation = [ 'relu' , 'logistic']\n",
        "optimizer = ['adam', 'lbfgs', 'sgd']\n",
        "batch_size = [ 32, 64, 128, 256 , 512]\n",
        "lr = [ 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwq4qgN0RWra"
      },
      "source": [
        "hidden_layer_sizes = []\n",
        "for i in hidden_units:\n",
        "  hidden_layer_sizes.append((i,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YeQCD3_v0OH"
      },
      "source": [
        "for i in hidden_units:\n",
        "  for j in hidden_units:\n",
        "    hidden_layer_sizes.append((i,j))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Jf4jZJwLvA"
      },
      "source": [
        "for i in hidden_units:\n",
        "  for j in hidden_units:\n",
        "    for k in hidden_units:\n",
        "      hidden_layer_sizes.append((i,j,k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhdAufeurOuR"
      },
      "source": [
        "Defining the search space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EAXLoQtR05c"
      },
      "source": [
        "search_space = {'hidden_layer_sizes': hidden_layer_sizes,\n",
        "                'activation': activation,\n",
        "                'solver': optimizer,\n",
        "                'learning_rate_init': lr,\n",
        "                'batch_size' : batch_size\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfhfCSp_TFuQ"
      },
      "source": [
        "NN_tpot = TPOTClassifier(generations = 1, population_size= 12, offspring_size= 6,\n",
        "                                 verbosity= 2, early_stop= 12,\n",
        "                                 config_dict={'sklearn.neural_network.MLPClassifier': search_space}, \n",
        "                                 cv = 5, scoring = 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdvvVhfFUA1n"
      },
      "source": [
        "NN_tpot.fit(x_train, y_train_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ae-cA3hUocC",
        "outputId": "c432864c-fb3b-4ff2-99b3-2a476250642b"
      },
      "source": [
        "accuracy = NN_tpot.score(x_test, y_test_gen)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.868421052631579\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}